{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8daa2248-2979-43f7-a945-85784fb716a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def70031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .env\n"
     ]
    }
   ],
   "source": [
    "%%writefile .env\n",
    "\n",
    "# TAVILY_API_KEY = your_key\n",
    "# JINA_API_KEY = your_key\n",
    "# CHROME_INSTANCE_PATH = /Applications/Google Chrome.app/Contents/MacOS/Google Chrome\n",
    "# BROWSER_HEADLESS=False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12c20d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     [telemetry] Anonymized telemetry enabled. See https://docs.browser-use.com/development/telemetry for more information.\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-west-2.amazonaws.com)\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-west-2.amazonaws.com)\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-west-2.amazonaws.com)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from src.workflow import run_agent_workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e915a3c-bb0d-4d3d-88cf-bfa0b61e8f9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_query = '''\n",
    "    Transformer 알고리즘과 현 시점에서 어떤식으로 변화 발전 하는지 알려줘\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bf1bef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO [src.workflow] \u001b[92m===== Starting workflow =====\u001b[0m\n",
      "\n",
      "INFO [src.workflow] \u001b[92m\n",
      "user input: \n",
      "    Transformer 알고리즘과 현 시점에서 어떤식으로 변화 발전 하는지 알려줘\n",
      "\u001b[0m\n",
      "\n",
      "INFO [src.graph.nodes] \u001b[92m===== Clarification agent starting task =====\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'./artifacts/' 폴더가 존재하지 않습니다.\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-west-2.amazonaws.com)\n",
      "--- 대화 턴 1 ---\n",
      "I'll help gather information about Transformer algorithms and their recent developments. Let me perform targeted searches."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO [src.agents.agents] \u001b[1m\n",
      "ToolUse - Tool Name: tavily_tool, Input: {'query': 'Latest developments and advancements in Transformer architecture 2024-2025'}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stop reason: tool_use\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO [src.agents.agents] \u001b[1mToolUse - 도구 실행 결과를 대화에 추가했습니다.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Results: \n",
      "\n",
      " [{'titile': 'Latest Transformer Architecture Trends and Innovations 2024', 'url': 'https://moldstud.com/articles/p-latest-transformer-architecture-trends-and-innovations-2024', 'content': \"ArticlesDevelopers FAQNeural network developers questionsLatest Transformer Architecture Trends and Innovations 2024\\n\\nPublished on12 February 2025 by Grady Andersen & MoldStud Research Team\\n\\nLatest Transformer Architecture Trends and Innovations 2024\\n\\nExplore the latest trends, innovations, and applications in transformer architectures for 2024 to stay ahead in AI advancements. [...] I heard they're experimenting with transformer distillation techniques to compress models without losing too much performance. Could be handy for deployment on edge devices.\\n\\nDo you think these new trends will make transformers more accessible to developers who aren't deep into the NLP world?\\n\\nI think so! With advancements in pre-trained models and easier-to-use libraries, more devs will be able to leverage transformers for various tasks. [...] New methodologies have emerged, enhancing performance metrics and reducing computational costs. Researchers have focused on improving scalability and adaptability, addressing past limitations. For instance, variations that allow for dynamic attention mechanisms are gaining traction. These approaches facilitate better handling of long sequences and contextual nuances, which are critical in real-world applications. Whether it’s conversational agents or content generation, efficiency is paramount.\"}, {'titile': '[PDF] Transformer and Newer Architectures Spring 2025 Attendance:@964', 'url': 'https://deeplearning.cs.cmu.edu/S25/document/slides/lec19.transformer.pdf', 'content': 'Deep Learning Transformer and Newer Architectures Dareen Alharthi, Hao Chen Spring 2025 Attendance:@964 1 Content • Transformer Architecture • Improvements on Transformers • Transformer for different modalities • Parameter Efficient Tuning • Scaling Laws 2 Content • Transformer Architecture • Improvements on Transformers • Transformer for different modalities • Parameter Efficient Tuning • Scaling Laws 3 Why Transformer? [...] • The Conformer uses convolution layers to replace self-attention entirely • Conformer blocks have convolutional modules placed after the self-attention module • The Conformer architecture eliminates the need for Feed Forward modules • Conformer was primarily designed for computer vision tasks rather than speech recognition Content • Transformer Architecture • Improvements on Transformers • Transformer for different modalities • Parameter Efficient Tuning • Scaling Laws 92 Parameter Efficient [...] Overview • Architecture – Encoder-Decoder – Encoder-Only – Decoder-Only • Position Encoding – Relative Position Encoding – Rotary Position Encoding • Efficient Attention Mechanism – Linear Attention – Flash Attention – Grouped Query Attention – Multi Query Attention – Multi-head Latent Attention 60 Quadratic Complexity • Self-attention has quadratic complexity to input length – FLOPS • Many attempts for reducing the quadratic complexity to linear – Linear Attention – Flash Attention – Grouped'}]\n",
      "--- 대화 턴 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO [src.agents.agents] \u001b[1m\n",
      "ToolUse - Tool Name: python_repl_tool, Input: {'code': '# Result accumulation storage section\\nimport os\\nfrom datetime import datetime\\n\\n# Create artifacts directory\\nos.makedirs(\\'./artifacts\\', exist_ok=True)\\n\\n# Result file path\\nresults_file = \\'./artifacts/bg_info.txt\\'\\nbackup_file = \\'./artifacts/bg_info_backup_{}.txt\\'.format(datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\\n\\n# Current analysis parameters\\nstage_name = \"Latest Transformer developments 2024-2025\"\\nurl = \"https://moldstud.com/articles/p-latest-transformer-architecture-trends-and-innovations-2024\"\\nresult_description = \"\"\"Key findings from the search:\\n1. Recent Architectural Improvements:\\n- Dynamic attention mechanisms for better handling of long sequences\\n- Transformer distillation techniques for model compression\\n- Focus on improving scalability and adaptability\\n- Enhanced performance metrics with reduced computational costs\\n\\n2. New Efficient Attention Mechanisms:\\n- Linear Attention\\n- Flash Attention\\n- Grouped Query Attention\\n- Multi Query Attention\\n- Multi-head Latent Attention\\n\\n3. Position Encoding Advancements:\\n- Relative Position Encoding\\n- Rotary Position Encoding\\n\\n4. Architecture Variations:\\n- Encoder-Decoder\\n- Encoder-Only\\n- Decoder-Only\\n- Conformer architecture using convolution layers\"\"\"\\n\\nartifact_files = []\\n\\n# Direct generation of result text without using a function\\ncurrent_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\\ncurrent_result_text = \"\"\"\\n==================================================\\n## Search query: {0}\\n## URL: {1}\\n## Execution Time: {2}\\n--------------------------------------------------\\nResult Description: \\n{3}\\n\"\"\".format(stage_name, url, current_time, result_description)\\n\\nif artifact_files:\\n    current_result_text += \"--------------------------------------------------\\\\nGenerated Files:\\\\n\"\\n    for file_path, file_desc in artifact_files:\\n        current_result_text += \"- {} : {}\\\\n\".format(file_path, file_desc)\\n\\ncurrent_result_text += \"==================================================\\\\n\"\\n\\n# Backup existing result file and accumulate results\\nif os.path.exists(results_file):\\n    try:\\n        if os.path.getsize(results_file) > 0:\\n            with open(results_file, \\'r\\', encoding=\\'utf-8\\') as f_src:\\n                with open(backup_file, \\'w\\', encoding=\\'utf-8\\') as f_dst:\\n                    f_dst.write(f_src.read())\\n            print(\"Created backup of existing results file: {}\".format(backup_file))\\n    except Exception as e:\\n        print(\"Error occurred during file backup: {}\".format(e))\\n\\ntry:\\n    with open(results_file, \\'a\\', encoding=\\'utf-8\\') as f:\\n        f.write(current_result_text)\\n    print(\"Results successfully saved.\")\\nexcept Exception as e:\\n    print(\"Error occurred while saving results: {}\".format(e))\\n    try:\\n        temp_file = \\'./artifacts/result_emergency_{}.txt\\'.format(datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\\n        with open(temp_file, \\'w\\', encoding=\\'utf-8\\') as f:\\n            f.write(current_result_text)\\n        print(\"Results saved to temporary file: {}\".format(temp_file))\\n    except Exception as e2:\\n        print(\"Temporary file save also failed: {}\".format(e2))'}\u001b[0m\n",
      "\n",
      "INFO [src.tools.python_repl] \u001b[92m===== Executing Python code =====\u001b[0m\n",
      "\n",
      "INFO [src.tools.python_repl] \u001b[92m===== Code execution successful =====\u001b[0m\n",
      "\n",
      "INFO [src.tools.decorators] \u001b[91mCoder - Successfully executed:\n",
      "\n",
      "```python\n",
      "# Result accumulation storage section\n",
      "import os\n",
      "from datetime import datetime\n",
      "\n",
      "# Create artifacts directory\n",
      "os.makedirs('./artifacts', exist_ok=True)\n",
      "\n",
      "# Result file path\n",
      "results_file = './artifacts/bg_info.txt'\n",
      "backup_file = './artifacts/bg_info_backup_{}.txt'.format(datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
      "\n",
      "# Current analysis parameters\n",
      "stage_name = \"Latest Transformer developments 2024-2025\"\n",
      "url = \"https://moldstud.com/articles/p-latest-transformer-architecture-trends-and-innovations-2024\"\n",
      "result_description = \"\"\"Key findings from the search:\n",
      "1. Recent Architectural Improvements:\n",
      "- Dynamic attention mechanisms for better handling of long sequences\n",
      "- Transformer distillation techniques for model compression\n",
      "- Focus on improving scalability and adaptability\n",
      "- Enhanced performance metrics with reduced computational costs\n",
      "\n",
      "2. New Efficient Attention Mechanisms:\n",
      "- Linear Attention\n",
      "- Flash Attention\n",
      "- Grouped Query Attention\n",
      "- Multi Query Attention\n",
      "- Multi-head Latent Attention\n",
      "\n",
      "3. Position Encoding Advancements:\n",
      "- Relative Position Encoding\n",
      "- Rotary Position Encoding\n",
      "\n",
      "4. Architecture Variations:\n",
      "- Encoder-Decoder\n",
      "- Encoder-Only\n",
      "- Decoder-Only\n",
      "- Conformer architecture using convolution layers\"\"\"\n",
      "\n",
      "artifact_files = []\n",
      "\n",
      "# Direct generation of result text without using a function\n",
      "current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
      "current_result_text = \"\"\"\n",
      "==================================================\n",
      "## Search query: {0}\n",
      "## URL: {1}\n",
      "## Execution Time: {2}\n",
      "--------------------------------------------------\n",
      "Result Description: \n",
      "{3}\n",
      "\"\"\".format(stage_name, url, current_time, result_description)\n",
      "\n",
      "if artifact_files:\n",
      "    current_result_text += \"--------------------------------------------------\\nGenerated Files:\\n\"\n",
      "    for file_path, file_desc in artifact_files:\n",
      "        current_result_text += \"- {} : {}\\n\".format(file_path, file_desc)\n",
      "\n",
      "current_result_text += \"==================================================\\n\"\n",
      "\n",
      "# Backup existing result file and accumulate results\n",
      "if os.path.exists(results_file):\n",
      "    try:\n",
      "        if os.path.getsize(results_file) > 0:\n",
      "            with open(results_file, 'r', encoding='utf-8') as f_src:\n",
      "                with open(backup_file, 'w', encoding='utf-8') as f_dst:\n",
      "                    f_dst.write(f_src.read())\n",
      "            print(\"Created backup of existing results file: {}\".format(backup_file))\n",
      "    except Exception as e:\n",
      "        print(\"Error occurred during file backup: {}\".format(e))\n",
      "\n",
      "try:\n",
      "    with open(results_file, 'a', encoding='utf-8') as f:\n",
      "        f.write(current_result_text)\n",
      "    print(\"Results successfully saved.\")\n",
      "except Exception as e:\n",
      "    print(\"Error occurred while saving results: {}\".format(e))\n",
      "    try:\n",
      "        temp_file = './artifacts/result_emergency_{}.txt'.format(datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
      "        with open(temp_file, 'w', encoding='utf-8') as f:\n",
      "            f.write(current_result_text)\n",
      "        print(\"Results saved to temporary file: {}\".format(temp_file))\n",
      "    except Exception as e2:\n",
      "        print(\"Temporary file save also failed: {}\".format(e2))\n",
      "```\n",
      "\u001b[0m\n",
      "\n",
      "INFO [src.tools.decorators] \u001b[94m\n",
      "Stdout: Results successfully saved.\n",
      "\u001b[0m\n",
      "2025-05-08 08:50:25.044 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-08 08:50:25.044 WARNING streamlit.runtime.state.session_state_proxy: Session state does not function when running a script without `streamlit run`\n",
      "\n",
      "INFO [src.agents.agents] \u001b[1mToolUse - 도구 실행 결과를 대화에 추가했습니다.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stop reason: tool_use\n",
      "--- 대화 턴 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO [src.agents.agents] \u001b[1m\n",
      "ToolUse - Tool Name: tavily_tool, Input: {'query': 'Transformer model practical applications and industry use cases 2025'}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stop reason: tool_use\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO [src.agents.agents] \u001b[1mToolUse - 도구 실행 결과를 대화에 추가했습니다.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Results: \n",
      "\n",
      " [{'titile': 'Transformers Model Impact on Manufacturing Trends - BytePlus', 'url': 'https://www.byteplus.com/en/topic/493850', 'content': 'Explore how the Transformers Model is shaping manufacturing trends and practices in 2025.'}, {'titile': 'What is a Transformer Model? Components, Innovations & Use Cases', 'url': 'https://www.ai21.com/knowledge/tranformer-model/', 'content': 'These advancements may enable businesses to scale AI deployments more effectively while improving efficiency, accuracy, and adaptability.\\nDiscover more\\n\\nLabs Insights LLM\\nApr 7, 2025\\n### RAG Evaluation: You’re Doing It Wrong\\n\\nCompany\\nMar 27, 2025\\n### AI21 Joins NVIDIA Inception for Enterprise AI [...] This article explores transformer models in depth, covering their definition, capabilities, core components, recent innovations, and practical applications in transforming industries from customer service to healthcare.\\nWhat is a transformer model? [...] Unlike RNNs and CNNs, transformers analyze entire input sequences at once using self-attention, which allows them to capture complex relationships in data more effectively. This makes them especially well-suited for enterprise applications such as contract analysis, AI chatbots, and multilingual translation. That said, their large size and resource requirements can pose scalability challenges in production environments.\\nTransformer model use cases'}, {'titile': 'Top 10 Generative AI Applications Use Cases & Examples [2025]', 'url': 'https://redblink.com/generative-ai-applications-use-cases/', 'content': 'Generative AI is poised to transform numerous industries, including surveillance, healthcare, marketing, advertising, education, gaming, communication, and'}, {'titile': 'AI Text Generators in 2025: Market Trends, Use Cases ... - ProfileTree', 'url': 'https://profiletree.com/ai-text-generators-market-trends-use-cases/', 'content': 'Understanding the technology behind AI text generators helps businesses evaluate potential solutions and implementation strategies:\\n\\nTransformer Architecture: Most modern AI text generators use transformer-based models that employ self-attention mechanisms to process and generate text. This architecture allows the model to consider context bidirectionally, resulting in more coherent and relevant outputs.\\n\\nPretraining and Fine-Tuning Pipeline:\\n\\nProminent Model Categories [...] Bidirectional Models (e.g., BERT derivatives): Analyse context from both directions simultaneously, making them particularly effective for text understanding, classification, and targeted response generation.\\n\\nSequence-to-Sequence Models (e.g., T5): Convert input sequences to output sequences, making them versatile for translation, summarisation, and structured text transformation tasks.\\n\\nLeading AI Text Generation Models'}, {'titile': 'What Are Transformer Models? Use Cases and Examples - Cohere', 'url': 'https://cohere.com/blog/transformer-model', 'content': 'Advanced Retrieval Models\\n\\n\\n\\nEmbed\\n\\nA leading multimodal search and retrieval tool\\n\\nRerank\\n\\nA powerful model that provides a semantic boost to search quality\\n\\nWorkplace Systems\\n\\n\\n\\nNorth\\n\\nAn integrated AI platform that empowers modern workers to do more\\n\\nCompass\\n\\nAn intelligent search and discovery system to surface business insights\\n\\nCustomization\\n\\nPricing\\n\\nSolutions\\n\\nIndustries\\n\\nFinancial Services\\n\\nHealthcare and Life Sciences\\n\\nManufacturing\\n\\nEnergy and Utilities\\n\\nPublic Sector\\n\\nSecurity [...] On-Demand Events\\n\\nCompany\\n\\nCompany\\n\\nAbout\\n\\nCareers\\n\\nNewsroom\\n\\nSign in\\n\\nWhat are transformer models? Use cases and examples\\n\\nDec 20, 2024\\n\\nTransformer models are deep learning neural networks, specializing in tracking relationships in sequential data like words in a sentence.\\n\\nShare:\\n\\nReady to put AI to work?\\n\\nProducts\\n\\nNorth\\n\\nCompass\\n\\nCommand\\n\\nEmbed\\n\\nRerank\\n\\nCustomization\\n\\nFine-tuning\\n\\nPricing\\n\\nDeployment Options\\n\\nCohere in Slack\\n\\nSolutions\\n\\nEnergy and Utilities\\n\\nFinancial Services [...] LLM University\\n\\nDocumentation\\n\\nRelease Notes\\n\\nAbout\\n\\nCareers\\n\\nResearch\\n\\nNewsroom\\n\\nPartners\\n\\nSecurity\\n\\nTrust Center\\n\\nAI moves fast\\n\\nWe’ll keep you up to date with the latest.\\n\\n\\n\\nCohere © 2025\\n\\nPrivacy\\n\\nTerms of Use'}]\n",
      "--- 대화 턴 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO [src.agents.agents] \u001b[1m\n",
      "ToolUse - Tool Name: python_repl_tool, Input: {'code': '# Result accumulation storage section\\nimport os\\nfrom datetime import datetime\\n\\n# Create artifacts directory\\nos.makedirs(\\'./artifacts\\', exist_ok=True)\\n\\n# Result file path\\nresults_file = \\'./artifacts/bg_info.txt\\'\\nbackup_file = \\'./artifacts/bg_info_backup_{}.txt\\'.format(datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\\n\\n# Current analysis parameters\\nstage_name = \"Transformer applications and industry use cases 2025\"\\nurl = \"https://www.ai21.com/knowledge/tranformer-model/\"\\nresult_description = \"\"\"Key findings about current Transformer applications and developments:\\n\\n1. Industry Applications:\\n- Enterprise applications: Contract analysis, AI chatbots, multilingual translation\\n- Healthcare and Life Sciences\\n- Manufacturing and Industry\\n- Financial Services\\n- Public Sector applications\\n\\n2. Technical Advancements:\\n- Bidirectional Models (BERT derivatives): Enhanced context understanding\\n- Sequence-to-Sequence Models (T5): Improved translation and summarization\\n- Advanced Retrieval Models: Better search and information retrieval\\n- Multimodal capabilities: Handling different types of data\\n\\n3. Implementation Considerations:\\n- Scalability challenges in production environments due to resource requirements\\n- Focus on efficiency and resource optimization\\n- Enterprise AI deployment strategies\\n- Integration with existing systems\"\"\"\\n\\nartifact_files = []\\n\\n# Direct generation of result text without using a function\\ncurrent_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\\ncurrent_result_text = \"\"\"\\n==================================================\\n## Search query: {0}\\n## URL: {1}\\n## Execution Time: {2}\\n--------------------------------------------------\\nResult Description: \\n{3}\\n\"\"\".format(stage_name, url, current_time, result_description)\\n\\nif artifact_files:\\n    current_result_text += \"--------------------------------------------------\\\\nGenerated Files:\\\\n\"\\n    for file_path, file_desc in artifact_files:\\n        current_result_text += \"- {} : {}\\\\n\".format(file_path, file_desc)\\n\\ncurrent_result_text += \"==================================================\\\\n\"\\n\\n# Backup existing result file and accumulate results\\nif os.path.exists(results_file):\\n    try:\\n        if os.path.getsize(results_file) > 0:\\n            with open(results_file, \\'r\\', encoding=\\'utf-8\\') as f_src:\\n                with open(backup_file, \\'w\\', encoding=\\'utf-8\\') as f_dst:\\n                    f_dst.write(f_src.read())\\n            print(\"Created backup of existing results file: {}\".format(backup_file))\\n    except Exception as e:\\n        print(\"Error occurred during file backup: {}\".format(e))\\n\\ntry:\\n    with open(results_file, \\'a\\', encoding=\\'utf-8\\') as f:\\n        f.write(current_result_text)\\n    print(\"Results successfully saved.\")\\nexcept Exception as e:\\n    print(\"Error occurred while saving results: {}\".format(e))\\n    try:\\n        temp_file = \\'./artifacts/result_emergency_{}.txt\\'.format(datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\\n        with open(temp_file, \\'w\\', encoding=\\'utf-8\\') as f:\\n            f.write(current_result_text)\\n        print(\"Results saved to temporary file: {}\".format(temp_file))\\n    except Exception as e2:\\n        print(\"Temporary file save also failed: {}\".format(e2))'}\u001b[0m\n",
      "\n",
      "INFO [src.tools.python_repl] \u001b[92m===== Executing Python code =====\u001b[0m\n",
      "\n",
      "INFO [src.tools.python_repl] \u001b[92m===== Code execution successful =====\u001b[0m\n",
      "\n",
      "INFO [src.tools.decorators] \u001b[91mCoder - Successfully executed:\n",
      "\n",
      "```python\n",
      "# Result accumulation storage section\n",
      "import os\n",
      "from datetime import datetime\n",
      "\n",
      "# Create artifacts directory\n",
      "os.makedirs('./artifacts', exist_ok=True)\n",
      "\n",
      "# Result file path\n",
      "results_file = './artifacts/bg_info.txt'\n",
      "backup_file = './artifacts/bg_info_backup_{}.txt'.format(datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
      "\n",
      "# Current analysis parameters\n",
      "stage_name = \"Transformer applications and industry use cases 2025\"\n",
      "url = \"https://www.ai21.com/knowledge/tranformer-model/\"\n",
      "result_description = \"\"\"Key findings about current Transformer applications and developments:\n",
      "\n",
      "1. Industry Applications:\n",
      "- Enterprise applications: Contract analysis, AI chatbots, multilingual translation\n",
      "- Healthcare and Life Sciences\n",
      "- Manufacturing and Industry\n",
      "- Financial Services\n",
      "- Public Sector applications\n",
      "\n",
      "2. Technical Advancements:\n",
      "- Bidirectional Models (BERT derivatives): Enhanced context understanding\n",
      "- Sequence-to-Sequence Models (T5): Improved translation and summarization\n",
      "- Advanced Retrieval Models: Better search and information retrieval\n",
      "- Multimodal capabilities: Handling different types of data\n",
      "\n",
      "3. Implementation Considerations:\n",
      "- Scalability challenges in production environments due to resource requirements\n",
      "- Focus on efficiency and resource optimization\n",
      "- Enterprise AI deployment strategies\n",
      "- Integration with existing systems\"\"\"\n",
      "\n",
      "artifact_files = []\n",
      "\n",
      "# Direct generation of result text without using a function\n",
      "current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
      "current_result_text = \"\"\"\n",
      "==================================================\n",
      "## Search query: {0}\n",
      "## URL: {1}\n",
      "## Execution Time: {2}\n",
      "--------------------------------------------------\n",
      "Result Description: \n",
      "{3}\n",
      "\"\"\".format(stage_name, url, current_time, result_description)\n",
      "\n",
      "if artifact_files:\n",
      "    current_result_text += \"--------------------------------------------------\\nGenerated Files:\\n\"\n",
      "    for file_path, file_desc in artifact_files:\n",
      "        current_result_text += \"- {} : {}\\n\".format(file_path, file_desc)\n",
      "\n",
      "current_result_text += \"==================================================\\n\"\n",
      "\n",
      "# Backup existing result file and accumulate results\n",
      "if os.path.exists(results_file):\n",
      "    try:\n",
      "        if os.path.getsize(results_file) > 0:\n",
      "            with open(results_file, 'r', encoding='utf-8') as f_src:\n",
      "                with open(backup_file, 'w', encoding='utf-8') as f_dst:\n",
      "                    f_dst.write(f_src.read())\n",
      "            print(\"Created backup of existing results file: {}\".format(backup_file))\n",
      "    except Exception as e:\n",
      "        print(\"Error occurred during file backup: {}\".format(e))\n",
      "\n",
      "try:\n",
      "    with open(results_file, 'a', encoding='utf-8') as f:\n",
      "        f.write(current_result_text)\n",
      "    print(\"Results successfully saved.\")\n",
      "except Exception as e:\n",
      "    print(\"Error occurred while saving results: {}\".format(e))\n",
      "    try:\n",
      "        temp_file = './artifacts/result_emergency_{}.txt'.format(datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
      "        with open(temp_file, 'w', encoding='utf-8') as f:\n",
      "            f.write(current_result_text)\n",
      "        print(\"Results saved to temporary file: {}\".format(temp_file))\n",
      "    except Exception as e2:\n",
      "        print(\"Temporary file save also failed: {}\".format(e2))\n",
      "```\n",
      "\u001b[0m\n",
      "\n",
      "INFO [src.tools.decorators] \u001b[94m\n",
      "Stdout: Created backup of existing results file: ./artifacts/bg_info_backup_20250508_085058.txt\n",
      "Results successfully saved.\n",
      "\u001b[0m\n",
      "2025-05-08 08:50:58.372 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "\n",
      "INFO [src.agents.agents] \u001b[1mToolUse - 도구 실행 결과를 대화에 추가했습니다.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stop reason: tool_use\n",
      "--- 대화 턴 5 ---\n",
      "\n",
      "\n",
      "{\"questions\": [\n",
      "    \"1. 트랜스포머 모델의 어떤 특정 응용 분야에 가장 관심이 있으신가요? (예: 자연어처리, 컴퓨터 비전, 음성인식 등)\",\n",
      "    \"2. 최근 개발된 효율적인 어텐션 메커니즘 중 특별히 더 자세히 알고 싶은 부분이 있으신가요? (Linear Attention, Flash Attention, Grouped Query Attention 등)\",\n",
      "    \"3. 트랜스포머 모델의 실제 구현이나 학습에 관심이 있으신가요, 아니면 이론적인 이해에 더 중점을 두고 계신가요?\",\n",
      "    \"4. 모델의 크기와 계산 효율성 측면에서 특별히 고려하고 계신 제약사항이 있으신가요?\"\n",
      "]}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO [src.agents.agents] \u001b[4mToolUse - 최종 응답을 받았습니다.\u001b[0m\n",
      "\n",
      "INFO [src.graph.nodes] Research agent completed task\n",
      "\n",
      "INFO [src.graph.nodes] Research agent response: \n",
      "\n",
      "{\"questions\": [\n",
      "    \"1. 트랜스포머 모델의 어떤 특정 응용 분야에 가장 관심이 있으신가요? (예: 자연어처리, 컴퓨터 비전, 음성인식 등)\",\n",
      "    \"2. 최근 개발된 효율적인 어텐션 메커니즘 중 특별히 더 자세히 알고 싶은 부분이 있으신가요? (Linear Attention, Flash Attention, Grouped Query Attention 등)\",\n",
      "    \"3. 트랜스포머 모델의 실제 구현이나 학습에 관심이 있으신가요, 아니면 이론적인 이해에 더 중점을 두고 계신가요?\",\n",
      "    \"4. 모델의 크기와 계산 효율성 측면에서 특별히 고려하고 계신 제약사항이 있으신가요?\"\n",
      "]}\n",
      "\n",
      "INFO [src.workflow] \u001b[92m===== Workflow completed successfully =====\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stop reason: end_turn\n",
      "최종 응답을 받았습니다.\n",
      "\n",
      "=== 대화 완료 ===\n",
      "최종 응답:\n",
      " {'text': '\\n\\n{\"questions\": [\\n    \"1. 트랜스포머 모델의 어떤 특정 응용 분야에 가장 관심이 있으신가요? (예: 자연어처리, 컴퓨터 비전, 음성인식 등)\",\\n    \"2. 최근 개발된 효율적인 어텐션 메커니즘 중 특별히 더 자세히 알고 싶은 부분이 있으신가요? (Linear Attention, Flash Attention, Grouped Query Attention 등)\",\\n    \"3. 트랜스포머 모델의 실제 구현이나 학습에 관심이 있으신가요, 아니면 이론적인 이해에 더 중점을 두고 계신가요?\",\\n    \"4. 모델의 크기와 계산 효율성 측면에서 특별히 고려하고 계신 제약사항이 있으신가요?\"\\n]}', 'reasoning': '', 'signature': '', 'toolUse': None, 'stop_reason': 'end_turn'}\n",
      "메시지:\n",
      " {'content': [{'text': '\\n\\n{\"questions\": [\\n    \"1. 트랜스포머 모델의 어떤 특정 응용 분야에 가장 관심이 있으신가요? (예: 자연어처리, 컴퓨터 비전, 음성인식 등)\",\\n    \"2. 최근 개발된 효율적인 어텐션 메커니즘 중 특별히 더 자세히 알고 싶은 부분이 있으신가요? (Linear Attention, Flash Attention, Grouped Query Attention 등)\",\\n    \"3. 트랜스포머 모델의 실제 구현이나 학습에 관심이 있으신가요, 아니면 이론적인 이해에 더 중점을 두고 계신가요?\",\\n    \"4. 모델의 크기와 계산 효율성 측면에서 특별히 고려하고 계신 제약사항이 있으신가요?\"\\n]}'}], 'role': 'assistant'}\n",
      "result {'content': [{'text': '\\n\\n{\"questions\": [\\n    \"1. 트랜스포머 모델의 어떤 특정 응용 분야에 가장 관심이 있으신가요? (예: 자연어처리, 컴퓨터 비전, 음성인식 등)\",\\n    \"2. 최근 개발된 효율적인 어텐션 메커니즘 중 특별히 더 자세히 알고 싶은 부분이 있으신가요? (Linear Attention, Flash Attention, Grouped Query Attention 등)\",\\n    \"3. 트랜스포머 모델의 실제 구현이나 학습에 관심이 있으신가요, 아니면 이론적인 이해에 더 중점을 두고 계신가요?\",\\n    \"4. 모델의 크기와 계산 효율성 측면에서 특별히 고려하고 계신 제약사항이 있으신가요?\"\\n]}'}], 'role': 'assistant'}\n",
      "\n",
      "=== Conversation History ===\n",
      "result {'TEAM_MEMBERS': ['researcher', 'coder', 'browser', 'reporter'], 'deep_thinking_mode': True, 'search_before_planning': False, 'messages': [{'role': 'user', 'content': [{'text': 'Response from clarifier:\\n\\n<response>\\n\\n\\n{\"questions\": [\\n    \"1. 트랜스포머 모델의 어떤 특정 응용 분야에 가장 관심이 있으신가요? (예: 자연어처리, 컴퓨터 비전, 음성인식 등)\",\\n    \"2. 최근 개발된 효율적인 어텐션 메커니즘 중 특별히 더 자세히 알고 싶은 부분이 있으신가요? (Linear Attention, Flash Attention, Grouped Query Attention 등)\",\\n    \"3. 트랜스포머 모델의 실제 구현이나 학습에 관심이 있으신가요, 아니면 이론적인 이해에 더 중점을 두고 계신가요?\",\\n    \"4. 모델의 크기와 계산 효율성 측면에서 특별히 고려하고 계신 제약사항이 있으신가요?\"\\n]}\\n</response>\\n\\n*Please execute the next step.*'}]}], 'messages_name': 'researcher', 'history': [{'agent': 'clarifier', 'message': '\\n\\n{\"questions\": [\\n    \"1. 트랜스포머 모델의 어떤 특정 응용 분야에 가장 관심이 있으신가요? (예: 자연어처리, 컴퓨터 비전, 음성인식 등)\",\\n    \"2. 최근 개발된 효율적인 어텐션 메커니즘 중 특별히 더 자세히 알고 싶은 부분이 있으신가요? (Linear Attention, Flash Attention, Grouped Query Attention 등)\",\\n    \"3. 트랜스포머 모델의 실제 구현이나 학습에 관심이 있으신가요, 아니면 이론적인 이해에 더 중점을 두고 계신가요?\",\\n    \"4. 모델의 크기와 계산 효율성 측면에서 특별히 고려하고 계신 제약사항이 있으신가요?\"\\n]}'}], 'clues': '\\n\\nHere is clues form clarifier:\\n\\n<clues>\\n\\n\\n{\"questions\": [\\n    \"1. 트랜스포머 모델의 어떤 특정 응용 분야에 가장 관심이 있으신가요? (예: 자연어처리, 컴퓨터 비전, 음성인식 등)\",\\n    \"2. 최근 개발된 효율적인 어텐션 메커니즘 중 특별히 더 자세히 알고 싶은 부분이 있으신가요? (Linear Attention, Flash Attention, Grouped Query Attention 등)\",\\n    \"3. 트랜스포머 모델의 실제 구현이나 학습에 관심이 있으신가요, 아니면 이론적인 이해에 더 중점을 두고 계신가요?\",\\n    \"4. 모델의 크기와 계산 효율성 측면에서 특별히 고려하고 계신 제약사항이 있으신가요?\"\\n]}\\n</clues>\\n\\n', 'request': '\\n    Transformer 알고리즘과 현 시점에서 어떤식으로 변화 발전 하는지 알려줘\\n'}\n",
      "===\n",
      "agent: clarifier\n",
      "message: \n",
      "\n",
      "{\"questions\": [\n",
      "    \"1. 트랜스포머 모델의 어떤 특정 응용 분야에 가장 관심이 있으신가요? (예: 자연어처리, 컴퓨터 비전, 음성인식 등)\",\n",
      "    \"2. 최근 개발된 효율적인 어텐션 메커니즘 중 특별히 더 자세히 알고 싶은 부분이 있으신가요? (Linear Attention, Flash Attention, Grouped Query Attention 등)\",\n",
      "    \"3. 트랜스포머 모델의 실제 구현이나 학습에 관심이 있으신가요, 아니면 이론적인 이해에 더 중점을 두고 계신가요?\",\n",
      "    \"4. 모델의 크기와 계산 효율성 측면에서 특별히 고려하고 계신 제약사항이 있으신가요?\"\n",
      "]}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def remove_artifact_folder(folder_path=\"./artifacts/\"):\n",
    "    \"\"\"\n",
    "    ./artifact/ 폴더가 존재하면 삭제하는 함수\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): 삭제할 폴더 경로\n",
    "    \"\"\"\n",
    "    if os.path.exists(folder_path):\n",
    "        print(f\"'{folder_path}' 폴더를 삭제합니다...\")\n",
    "        try:\n",
    "            # 폴더와 그 내용을 모두 삭제\n",
    "            shutil.rmtree(folder_path)\n",
    "            print(f\"'{folder_path}' 폴더가 성공적으로 삭제되었습니다.\")\n",
    "        except Exception as e:\n",
    "            print(f\"오류 발생: {e}\")\n",
    "    else:\n",
    "        print(f\"'{folder_path}' 폴더가 존재하지 않습니다.\")\n",
    "\n",
    "\n",
    "#import nest_asyncio\n",
    "#nest_asyncio.apply()\n",
    "\n",
    "remove_artifact_folder()\n",
    "\n",
    "result = run_agent_workflow(\n",
    "    user_input=user_query,\n",
    "    debug=False\n",
    ")\n",
    "\n",
    "# Print the conversation history\n",
    "print(\"\\n=== Conversation History ===\")\n",
    "print (\"result\", result)\n",
    "for history in result[\"history\"]:\n",
    "\n",
    "    print (\"===\")\n",
    "    print (f'agent: {history[\"agent\"]}')\n",
    "    print (f'message: {history[\"message\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e4a3c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {'TEAM_MEMBERS': ['researcher', 'coder', 'browser', 'reporter'],\n",
    "'deep_thinking_mode': True, 'search_before_planning': False, \n",
    "'messages': [{'role': 'user', 'content': [{'text': 'Response from clarifier:\\n\\n<response>\\n\\n\\n{\"questions\": [\\n    \"1. 트랜스포머 모델의 어떤 특정 응용 분야에 가장 관심이 있으신가요? (예: 자연어처리, 컴퓨터 비전, 음성인식 등)\",\\n    \"2. 최근 개발된 효율적인 어텐션 메커니즘 중 특별히 더 자세히 알고 싶은 부분이 있으신가요? (Linear Attention, Flash Attention, Grouped Query Attention 등)\",\\n    \"3. 트랜스포머 모델의 실제 구현이나 학습에 관심이 있으신가요, 아니면 이론적인 이해에 더 중점을 두고 계신가요?\",\\n    \"4. 모델의 크기와 계산 효율성 측면에서 특별히 고려하고 계신 제약사항이 있으신가요?\"\\n]}\\n</response>\\n\\n*Please execute the next step.*'}]}], 'messages_name': 'researcher', 'history': [{'agent': 'clarifier', 'message': '\\n\\n{\"questions\": [\\n    \"1. 트랜스포머 모델의 어떤 특정 응용 분야에 가장 관심이 있으신가요? (예: 자연어처리, 컴퓨터 비전, 음성인식 등)\",\\n    \"2. 최근 개발된 효율적인 어텐션 메커니즘 중 특별히 더 자세히 알고 싶은 부분이 있으신가요? (Linear Attention, Flash Attention, Grouped Query Attention 등)\",\\n    \"3. 트랜스포머 모델의 실제 구현이나 학습에 관심이 있으신가요, 아니면 이론적인 이해에 더 중점을 두고 계신가요?\",\\n    \"4. 모델의 크기와 계산 효율성 측면에서 특별히 고려하고 계신 제약사항이 있으신가요?\"\\n]}'}], 'clues': '\\n\\nHere is clues form clarifier:\\n\\n<clues>\\n\\n\\n{\"questions\": [\\n    \"1. 트랜스포머 모델의 어떤 특정 응용 분야에 가장 관심이 있으신가요? (예: 자연어처리, 컴퓨터 비전, 음성인식 등)\",\\n    \"2. 최근 개발된 효율적인 어텐션 메커니즘 중 특별히 더 자세히 알고 싶은 부분이 있으신가요? (Linear Attention, Flash Attention, Grouped Query Attention 등)\",\\n    \"3. 트랜스포머 모델의 실제 구현이나 학습에 관심이 있으신가요, 아니면 이론적인 이해에 더 중점을 두고 계신가요?\",\\n    \"4. 모델의 크기와 계산 효율성 측면에서 특별히 고려하고 계신 제약사항이 있으신가요?\"\\n]}\\n</clues>\\n\\n', 'request': '\\n    Transformer 알고리즘과 현 시점에서 어떤식으로 변화 발전 하는지 알려줘\\n'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8e988e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['TEAM_MEMBERS', 'deep_thinking_mode', 'search_before_planning', 'messages', 'messages_name', 'history', 'clues', 'request'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1786afe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e08ab98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897130ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbba01f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590c0ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import src.config\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from src.config import TAVILY_MAX_RESULTS\n",
    "from src.tools.decorators import create_logged_tool\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be042a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "LoggedTavilySearch = create_logged_tool(TavilySearchResults)\n",
    "tavily_tool = LoggedTavilySearch(name=\"tavily_search\", max_results=TAVILY_MAX_RESULTS)\n",
    "def handle_tavily_tool(query):\n",
    "    '''\n",
    "    Use this tool to search the internet for real-time information, current events, or specific data. Provides relevant search results from Tavily's search engine API.\n",
    "    '''\n",
    "\n",
    "    print (query)\n",
    "\n",
    "    searched_content = tavily_tool.invoke({\"query\": query})\n",
    "    print (searched_content)\n",
    "    results = f\"\\n\\n# Relative Search Results\\n\\n{json.dumps([{'titile': elem['title'], 'content': elem['content']} for elem in searched_content], ensure_ascii=False)}\"\n",
    "    print (f'Search Results: \\n\\n {[{'titile': elem['title'], 'content': elem['content']} for elem in searched_content]}')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0053d88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = handle_tavily_tool(\n",
    "    query=\"korea reranker\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d676e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.crawler import Crawler\n",
    "# Initialize the crawler\n",
    "crawler = Crawler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f752a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://blog-ko.superb-ai.com/\"\n",
    "# Crawl the URL\n",
    "article = crawler.crawl(url)\n",
    "article.to_markdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd92b372",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (article.to_message()[-1][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd98d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = results.split(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f655c063",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = json.loads(aa[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b511b8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f23afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ( bb[1][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac8deea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from .article import Article\n",
    "# Jina 대신 newspaper3k 사용\n",
    "import newspaper\n",
    "from newspaper import Article as NewspaperArticle\n",
    "\n",
    "class Crawler:\n",
    "    def crawl(self, url: str) -> Article:\n",
    "        # newspaper3k를 사용하여 기사 추출\n",
    "        news_article = NewspaperArticle(url, language='ko')  # 한국어 언어 설정\n",
    "        news_article.download()\n",
    "        news_article.parse()\n",
    "        \n",
    "        # Article 객체 생성 및 반환\n",
    "        article = Article()\n",
    "        article.url = url\n",
    "        article.title = news_article.title\n",
    "        article.content = news_article.text\n",
    "        article.author = news_article.authors[0] if news_article.authors else \"\"\n",
    "        article.publish_date = news_article.publish_date\n",
    "        \n",
    "        # 이미지가 있는 경우\n",
    "        if news_article.top_image:\n",
    "            article.images = [news_article.top_image]\n",
    "        \n",
    "        return article\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) == 2:\n",
    "        url = sys.argv[1]\n",
    "    else:\n",
    "        url = \"https://fintel.io/zh-hant/s/br/nvdc34\"\n",
    "    crawler = Crawler()\n",
    "    article = crawler.crawl(url)\n",
    "    print(article.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06686fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bedrock-manus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
